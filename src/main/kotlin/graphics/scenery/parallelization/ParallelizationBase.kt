package graphics.scenery.parallelization

import graphics.scenery.Camera
import graphics.scenery.Mesh
import graphics.scenery.RichNode
import graphics.scenery.Scene
import graphics.scenery.VolumeManagerManager
import graphics.scenery.backends.Renderer
import graphics.scenery.natives.MPIJavaWrapper
import graphics.scenery.textures.Texture
import graphics.scenery.utils.SystemHelpers
import graphics.scenery.utils.extensions.fetchFromGPU
import graphics.scenery.utils.lazyLogger
import graphics.scenery.volumes.BufferedVolume
import graphics.scenery.volumes.DummyVolume
import graphics.scenery.volumes.Volume
import org.joml.Quaternionf
import org.joml.Vector3f
import org.joml.Vector3i
import java.nio.ByteBuffer
import java.nio.ByteOrder

/**
 * Data class representing MPI (Message Passing Interface) parameters.
 *
 * @property rank The rank of the current process.
 * @property commSize The total number of processes in the communicator.
 * @property nodeRank The rank of the process within its node.
 */
data class MPIParameters(
    val rank: Int,
    val commSize: Int,
    val nodeRank: Int
)

/**
 * Abstract class defining the basic parallel execution structure for distributed rendering.
 *
 * @property volumeManagerManager The manager responsible for handling volume data.
 * @property mpiParameters The MPI parameters for the current process.
 */
abstract class ParallelizationBase(var volumeManagerManager: VolumeManagerManager, val mpiParameters: MPIParameters, val scene: Scene) {

    val logger by lazyLogger()

    open val twoPassRendering = false
    open val explicitCompositingStep = false

    open val firstPassFlag = ""
    open val secondPassFlag = ""

    open val distributedColorsTextureName: String
        get() = if (explicitCompositingStep) {
            throw IllegalStateException("The parallelization strategy requires an explicit compositing step, but distributedColorsTextureName is not overridden.")
        } else {
            "distributedColors"
        }

    open val distributedDepthsTextureName: String
        get() = if (explicitCompositingStep) {
            throw IllegalStateException("The parallelization strategy requires an explicit compositing step, but distributedDepthsTextureName is not overridden.")
        } else {
            "distributedDepths"
        }

    open val compositedColorsTextureName: String
        get() = if (explicitCompositingStep) {
            throw IllegalStateException("The parallelization strategy requires an explicit compositing step, but compositedColorsTextureName is not overridden.")
        } else {
            "compositedColors"
        }

    open val compositedDepthsTextureName: String
        get() = if (explicitCompositingStep) {
            throw IllegalStateException("The parallelization strategy requires an explicit compositing step, but compositedDepthsTextureName is not overridden.")
        } else {
            "compositedDepths"
        }

    var firstPass = true
    var secondPass = false
    var compositingPass = false
    var finalOutputReady = false

    protected var videoStreamRunning = false

    var compositorNode: RichNode? = null

    protected open var windowWidth: Int = 0
    protected open var windowHeight: Int = 0

    var streamGeneratedData = false
    var saveGeneratedData = false
    private var displayGeneratedData = false
    var displayObject: Mesh? = null

    private var frameNumber = 0

    private var previousCameraPosition = Vector3f(0f, 0f, 0f)
    private var previousCameraRotation = Quaternionf()

    fun setDisplayGeneratedData(displayObject: Mesh) {
        displayGeneratedData = true
        this.displayObject = displayObject
    }

    /**
     * The final composited buffers generated by the parallel rendering strategy.
     *
     * The buffers must be in the following order:
     * 1. Color buffer
     * 2. Depth buffer (if any)
     * 3. Additional buffers, e.g., alpha (if any)
     */
    protected val finalBuffers: MutableList<ByteBuffer> = mutableListOf()

    protected fun isRootProcess(): Boolean {
        return mpiParameters.rank == rootRank
    }

    /**
     * Sets up the compositor node. Must be overridden if the derived class sets [explicitCompositingStep] to true.
     *
     * @return The compositor node.
     */
    open fun setupCompositor() : RichNode? {
        return null
    }

    init {
        compositorNode = setupCompositor()
        compositorNode?.let {
            compositorNode!!.visible = false

            scene.addChild(compositorNode!!)
        }

        volumeManagerManager.getVolumeManager().hub?.let {
            it.get<Renderer>()?.let { renderer ->
                windowWidth = renderer.window.width
                windowHeight = renderer.window.height
            } ?: run {
                throw RuntimeException("Please ensure that the ParallelizationBase class is initialized after the Renderer, with" +
                        "a valid and initialized VolumeManagerManager")
            }
        } ?: run {
            throw RuntimeException("Please ensure that the ParallelizationBase class is initialized after the Renderer, with" +
                    "a valid and initialized VolumeManagerManager")
        }
    }

    /**
     * Fetches the data generated in the first rendering pass in the form of a texture. Only called if [twoPassRendering] is true.
     *
     * @return The data from the first pass texture.
     * @throws RuntimeException if there is an error fetching the texture.
     */
    open fun getFirstPassData(): ByteBuffer {
        val firstPassTexture = volumeManagerManager.getFirstPassTextureOrNull()!!
        val textureFetched = firstPassTexture.fetchFromGPU()

        if (!textureFetched) {
            throw RuntimeException("Error fetching first pass texture.").also { it.printStackTrace() }
        }

        return firstPassTexture.contents!!
    }

    /**
     * Override to process first pass data if the renderer is using a 2-pass approach.
     *
     * @param data The data from the first pass.
     */
    open fun processFirstPassData(data: ByteBuffer) {

    }

    /**
     * Override to fetch additional textures (beyond color and depth) generated by the parallel rendering strategy before the
     * compositing stage.
     *
     * @return A list of additional texture data.
     */
    open fun fetchAdditionalTextureData(): List<ByteBuffer> {
        return emptyList()
    }

    /**
     * Override to insert any preprocessing required before rendered buffers are distributed for compositing.
     *
     * @param process The process to execute.
     */
    fun preProcessBeforeDistribute(process: () -> Unit) {
        try {
            process()
        } catch (e: Exception) {
            logger.error("Error in pre-processing before distribution: ${e.message}")
        }
    }

    /**
     * Distributes the buffers generated in the rendering process for compositing. This function is responsible for
     * invoking [uploadForCompositing] after distributing the buffers.
     *
     * @param buffers The buffers to distribute.
     */
    abstract fun distributeForCompositing(buffers: List<ByteBuffer>)

    /**
     * Gathers the composited output. This function is only executed if [explicitCompositingStep] is set to true.
     * It should be overridden to gather the composited output in parallel rendering strategies that involve an
     * explicit compositing step.
     *
     * The implementation of the function is responsible for storing the final gathered composited output buffers
     * in the [finalBuffers] list.
     */
    open fun gatherCompositedOutput(buffers: List<ByteBuffer>) {
        // Override to gather composited output if needed
    }

    /**
     * Uploads the data necessary for compositing. This function should be overridden to upload data and update necessary
     * camera parameters for compositing.
     *
     * @param buffersToUpload The buffers to upload.
     * @param camera The camera to update.
     * @param elementCounts If run-length encoding is used, the process-wise start points of the color data can be passed into this array. The size of array should be equal to the number of processes.
     */
    open fun uploadForCompositing(buffersToUpload: List<ByteBuffer>, camera: Camera, elementCounts: IntArray) {
        // Override to upload data and update necessary camera parameters for compositing
    }

    /**
     * Set the compositor activity status. If the parallel execution strategy contains an explicit compositing pass, this
     * function should be overridden to activate or deactivate the compositing shader based on the value of [setTo].
     *
     * @param setTo Boolean value to set the compositor activity status to.
     */
    open fun setCompositorActivityStatus(setTo: Boolean) {
        if (explicitCompositingStep) {
            throw UnsupportedOperationException("setCompositorActivityStatus must be overridden when explicitCompositingStep is true.")
        }
    }

    abstract fun streamOutput()

    /**
     * The main function controlling the parallel rendering execution. This function is called after the rendering process
     * is complete and is responsible for fetching the rendered buffers, distributing them for compositing, and orchestrating
     * the renderer to execute the rendering and compositing processes in the correct order.
     */
    fun postRender() {

        if(!twoPassRendering) {
            val buffersToDistribute: MutableList<ByteBuffer> = mutableListOf()
            val colorTexture = volumeManagerManager.getColorTextureOrNull()!!
            var textureFetched = colorTexture.fetchFromGPU()
            if (!textureFetched) {
                throw RuntimeException("Error fetching color texture.").also { it.printStackTrace() }
            }

            buffersToDistribute.add(colorTexture.contents!!)

            // can't assume that a depth texture will always be present
            val depthTexture = volumeManagerManager.getDepthTextureOrNull()
            if(depthTexture != null) {
                textureFetched = depthTexture.fetchFromGPU()
                if (!textureFetched) {
                    throw RuntimeException("Error fetching depth texture.").also { it.printStackTrace() }
                }

                buffersToDistribute.add(depthTexture.contents!!)
            }

            fetchAdditionalTextureData().forEach {
                buffersToDistribute.add(it)
            }

            distributeForCompositing(buffersToDistribute)

            if(explicitCompositingStep) {
                compositingPass = true
                firstPass = false
                volumeManagerManager.getVolumeManager().shaderProperties[firstPassFlag] = false
            }

            //TODO: is this correct for cases where there is an explicit compositing step?
            finalOutputReady = true
        } else {
            if(firstPass) {
                // Data generated in the first pass is fetched and processed
                val firstPassData = getFirstPassData()
                processFirstPassData(firstPassData)

                firstPass = false
                secondPass = true

                volumeManagerManager.getVolumeManager().shaderProperties[firstPassFlag] = false
                volumeManagerManager.getVolumeManager().shaderProperties[secondPassFlag] = true
            } else if(secondPass) {
                // Final generated (rendered) buffers are fetched and distributed for compositing

                val buffersToDistribute: MutableList<ByteBuffer> = mutableListOf()
                val colorTexture = volumeManagerManager.getColorTextureOrNull()!!
                var textureFetched = colorTexture.fetchFromGPU()
                if (!textureFetched) {
                    throw RuntimeException("Error fetching color texture.").also { it.printStackTrace() }
                }

                buffersToDistribute.add(colorTexture.contents!!)

                // safe to assume that a 2-pass approach will always have a depth texture
                val depthTexture = volumeManagerManager.getDepthTextureOrNull()!!
                textureFetched = depthTexture.fetchFromGPU()
                if (!textureFetched) {
                    throw RuntimeException("Error fetching depth texture.").also { it.printStackTrace() }
                }

                buffersToDistribute.add(depthTexture.contents!!)

                fetchAdditionalTextureData().forEach {
                    buffersToDistribute.add(it)
                }

                distributeForCompositing(buffersToDistribute)
                // the distribute code will then call the [uploadForCompositing] function which will upload the data necessary for compositing

                if(explicitCompositingStep) {
                    secondPass = false
                    compositingPass = true
                    setCompositorActivityStatus(true)
                    volumeManagerManager.getVolumeManager().shaderProperties[secondPassFlag] = false
                } else {
                    secondPass = false
                    firstPass = true
                    finalOutputReady = true
                    volumeManagerManager.getVolumeManager().shaderProperties[firstPassFlag] = true
                }
            }
        }

        if(explicitCompositingStep && compositingPass) {
            val compositedBuffers: MutableList<ByteBuffer> = mutableListOf()

            // The compositing pass just completed
            val compositedColors = compositorNode!!.material().textures[compositedColorsTextureName]!!
            // safe to assume that an explicit compositing step will always require a depth texture
            val compositedDepths = compositorNode!!.material().textures[compositedDepthsTextureName]!!
            var textureFetched = compositedColors.fetchFromGPU()
            if (!textureFetched) {
                throw RuntimeException("Error fetching composited colors texture.").also { it.printStackTrace() }
            }

            compositedBuffers.add(compositedColors.contents!!)

            textureFetched = compositedDepths.fetchFromGPU()
            if (!textureFetched) {
                throw RuntimeException("Error fetching composited depths texture.").also { it.printStackTrace() }
            }

            compositedBuffers.add(compositedDepths.contents!!)

            compositingPass = false
            setCompositorActivityStatus(false)
            gatherCompositedOutput(compositedBuffers)
            finalOutputReady = true
            firstPass = true
            volumeManagerManager.getVolumeManager().shaderProperties[firstPassFlag] = true
        }

    }

    fun processCompositedOutput() {
        if((this is TestParallelization) || (isRootProcess() && finalOutputReady)) {
            finalOutputReady = false
            if(displayGeneratedData) {
                displayObject?.let {
                    val bufferLE = finalBuffers.first().order(ByteOrder.LITTLE_ENDIAN)
                    //TODO: fix memory leak on GPU caused my creating a new texture each time
                    displayObject!!.material().textures["diffuse"] =
                        Texture(Vector3i(windowWidth, windowHeight, 1), 4, contents = bufferLE, mipmap = true)

                }
            }

            if(saveGeneratedData) {
                finalBuffers.forEachIndexed { index, buffer ->
                    SystemHelpers.dumpToFile(buffer, "composited_output_frame_${frameNumber}_$index.raw")
                }
            }

            if(streamGeneratedData) {
                streamOutput()
            }
        }

        frameNumber++
        finalBuffers.clear()
    }

    fun synchronizeCamera() {
        val cameraData = ByteBuffer.allocate(7 * 4).order(ByteOrder.LITTLE_ENDIAN)

        if (scene.findObserver() == null) {
            IllegalStateException("Camera not found in scene")
        }
        val camera = scene.findObserver() as Camera

        cameraData.putFloat(camera.spatial().position.x)
        cameraData.putFloat(camera.spatial().position.y)
        cameraData.putFloat(camera.spatial().position.z)
        cameraData.putFloat(camera.spatial().rotation.x)
        cameraData.putFloat(camera.spatial().rotation.y)
        cameraData.putFloat(camera.spatial().rotation.z)
        cameraData.putFloat(camera.spatial().rotation.w)
        val cameraByteArray = cameraData.array()

        if(mpiParameters.rank != rootRank) {
            logger.debug("On rank: ${mpiParameters.rank}, before broadcast camera pose was: ${camera.spatial().position}, ${camera.spatial().rotation}")
        }

        MPIJavaWrapper.bcast(cameraByteArray, 0)
        // since the array was updated in-place, we have the changed camera position

        if(mpiParameters.rank != rootRank) {
            logger.debug("On rank: ${mpiParameters.rank}, after broadcast, camera pose is: ${camera.spatial().position}, ${camera.spatial().rotation}")
        }

        val newCameraData = ByteBuffer.wrap(cameraByteArray).order(ByteOrder.LITTLE_ENDIAN).asFloatBuffer()

        camera.spatial().position = Vector3f(newCameraData[0], newCameraData[1], newCameraData[2])
        camera.spatial().rotation = Quaternionf(newCameraData[3], newCameraData[4], newCameraData[5], newCameraData[6])

        previousCameraPosition = camera.spatial().position
        previousCameraRotation = camera.spatial().rotation
    }

    /**
     * Synchronizes the transfer function between the processes.
     * The root process uses the [DummyVolume] to access the latest transfer function from the client.
     * The root process serializes this transfer function and broadcasts it via MPI.
     * All processes then update each of their volumes with the received transfer function.
     */
    fun synchronizeTransferFunction(volumes: HashMap<Int, BufferedVolume?>) {
        val volumeManager = volumeManagerManager.getVolumeManager()

        // Only the root process serializes the transfer function
        val serializedTF = if(isRootProcess()) {
            val dummyVolume = scene.find("DummyVolume") as? DummyVolume
            if (dummyVolume == null) {
                throw IllegalStateException("DummyVolume not found in the scene. Please make sure client is running" +
                        " and connected, or use in testing mode by setting -Dscenery.LiV-Test-Benchmark=true")
            }

            val tfData = dummyVolume.transferFunction.controlPoints()

            ByteBuffer.allocate(tfData.size * 2 * 4).order(ByteOrder.LITTLE_ENDIAN).apply {
                tfData.forEach { cp ->
                    putFloat(cp.value)
                    putFloat(cp.factor)
                }
            }.array()
        } else {
            ByteArray(0)
        }

        // Broadcast the size first
        val tfSize = if (isRootProcess()) ByteBuffer.allocate(4).order(ByteOrder.LITTLE_ENDIAN).putInt(serializedTF.size).array() else ByteArray(4)
        MPIJavaWrapper.bcast(tfSize, 0)
        val tfSizeInt = ByteBuffer.wrap(tfSize).order(ByteOrder.LITTLE_ENDIAN).int

        // Prepare buffer for receiving/sending
        val tfBuffer = if (isRootProcess()) serializedTF else ByteArray(tfSizeInt)
        MPIJavaWrapper.bcast(tfBuffer, 0)

        for(i in 0 until volumes.size) {
            val tfData = ByteBuffer.wrap(tfBuffer).order(ByteOrder.LITTLE_ENDIAN).asFloatBuffer()

            val volume = volumes[i] as Volume

            volume.transferFunction.clear()

            for (i in 0 until tfSizeInt / 8) {
                volume.transferFunction.addControlPoint(tfData[i * 2], tfData[i * 2 + 1])
            }
        }
    }

    companion object {
        const val rootRank = 0
    }
}